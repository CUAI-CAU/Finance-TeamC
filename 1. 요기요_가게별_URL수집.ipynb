{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_reviews(location, food_category):\n",
    "    location\n",
    "    name = location.split(\" \")[1]\n",
    "    list_url = \"https://www.yogiyo.co.kr/mobile/#/\"\n",
    "    urls = []\n",
    "    df = pd.DataFrame(columns=['url', '개수충족'])\n",
    "\n",
    "    #### 주소 기준으로 초기화\n",
    "    driver = webdriver.Chrome('/Users/jijoonghong/Downloads/chromedriver')\n",
    "\n",
    "    driver.get(list_url)\n",
    "    time.sleep(8)\n",
    "    element = driver.find_element_by_name(\"address_input\")\n",
    "    element.clear()\n",
    "    element.send_keys(location)\n",
    "    btn = driver.find_element_by_css_selector(\"#button_search_address > button.btn.btn-default.ico-pick\")\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 리뷰 많은 순으로 sorting\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select/option[3]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # 카테고리 접속 및 가게 리스트 \n",
    "    driver.get(list_url + food_category)\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(last_height)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        scroll_down = 0\n",
    "        while scroll_down < 10:\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.2)\n",
    "            scroll_down += 1\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(1)\n",
    "        if new_height == last_height:\n",
    "            print(\"끝\")\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "    \n",
    "    store_list = driver.find_elements_by_xpath(\"//div[@class='item clearfix']\")\n",
    "    \n",
    "    return len(store_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url3(location, food_category, start, end):\n",
    "    name = location.split(\" \")[1]\n",
    "    list_url = \"https://www.yogiyo.co.kr/mobile/#/\"\n",
    "    urls = []\n",
    "    parsed_data = pd.read_csv(\"./강남구url/강남구_\"+food_category+\"_url.csv\")\n",
    "    stores = parsed_data['가게명'].tolist()\n",
    "    df = pd.DataFrame(columns=['url', '개수충족','가게명'])\n",
    "    \n",
    "    #### 주소 기준으로 초기화\n",
    "    driver = webdriver.Chrome('/Users/jijoonghong/Downloads/chromedriver')\n",
    "\n",
    "    driver.get(list_url)\n",
    "    time.sleep(8)\n",
    "    element = driver.find_element_by_name(\"address_input\")\n",
    "    element.clear()\n",
    "    element.send_keys(location)\n",
    "    btn = driver.find_element_by_css_selector(\"#button_search_address > button.btn.btn-default.ico-pick\")\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 리뷰 많은 순으로 sorting\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select/option[3]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[1]/div[2]/div/select').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # 카테고리 접속 및 가게 리스트 \n",
    "    driver.get(list_url + food_category) \n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(start, end)):\n",
    "            time.sleep(0.5)\n",
    "            is_valid = 1\n",
    "            path = '//*[@id=\"content\"]/div/div[5]/div/div/div[' + str(i) + ']/div'\n",
    "            \n",
    "            try:\n",
    "                store_name = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[5]/div/div/div['+str(i)+']/div/table/tbody/tr/td[2]/div/div[1]').text\n",
    "\n",
    "            except:\n",
    "                for j in range(int(i // 60)):\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    if i<480:\n",
    "                        time.sleep(i//60)\n",
    "                    else:\n",
    "                        time.sleep(8)\n",
    "            try:\n",
    "                store_name = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[5]/div/div/div['+str(i)+']/div/table/tbody/tr/td[2]/div/div[1]').text\n",
    "                n = driver.find_element_by_css_selector(\n",
    "                    \"#content > div > div:nth-child(5) > div > div > div:nth-child(\" + str(\n",
    "                        i) + \") > div > table > tbody > tr > td:nth-child(2) > div > div.stars > span:nth-child(2)\").text\n",
    "\n",
    "            except:\n",
    "                time.sleep(6)\n",
    "                store_name = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div[5]/div/div/div['+str(i)+']/div/table/tbody/tr/td[2]/div/div[1]').text\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                n = driver.find_element_by_css_selector(\n",
    "                    \"#content > div > div:nth-child(5) > div > div > div:nth-child(\" + str(\n",
    "                        i) + \") > div > table > tbody > tr > td:nth-child(2) > div > div.stars > span:nth-child(2)\").text\n",
    "            print(store_name)\n",
    "            if store_name in stores:\n",
    "                print(\"skip\")\n",
    "                continue\n",
    "                \n",
    "            some_tag = driver.find_element_by_xpath(path)\n",
    "            if n == \"\" or int(n.split(\" \")[1]) < 10:\n",
    "                is_valid = 0\n",
    "\n",
    "            # somthing element 까지 스크롤\n",
    "            action = ActionChains(driver)\n",
    "            action.move_to_element(some_tag).perform()\n",
    "            driver.find_element_by_xpath(path).click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            row = pd.DataFrame([(driver.current_url, is_valid, store_name)],columns=['url', '개수충족','가게명'])\n",
    "            print(row)\n",
    "            df = df.append(row)\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(3)\n",
    "    except:\n",
    "        df.to_csv(\"./temp/\"+location.split(\" \")[1]+\"_\"+food_category+\"_url_list2_비정상종료-\"+str(start)+\".csv\",\n",
    "              encoding='utf-8-sig')\n",
    "        \n",
    "    df.to_csv(\"./temp/\"+location.split(\" \")[1]+\"_\"+food_category+\"_url_list2-\"+str(start)+\".csv\",\n",
    "              encoding='utf-8-sig')\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(category):\n",
    "    driver = webdriver.Chrome('/Users/jijoonghong/Downloads/chromedriver')\n",
    "    df = pd.read_csv(\"./강남구_\"+category+\"_url_list.csv\")\n",
    "    urls = df['url'].tolist()\n",
    "    store_name = []\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(1.5)\n",
    "        try:\n",
    "            store_name.append(driver.find_element_by_xpath('//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[1]/span').text)\n",
    "        except:\n",
    "            print(url)\n",
    "    df['가게명']=store_name\n",
    "    df.to_csv(\"./강남구_\"+category+\"_url_list.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "categories = [\"프랜차이즈\", \"한식\", \"치킨\", \"피자양식\", \"중식\", \"일식돈까스\", \"족발보쌈\", \"야식\", \"분식\", \"카페디저트\", \"편의점\"]\n",
    "\n",
    "for cat in categories:\n",
    "    dic[cat] = num_of_reviews(\"서울특별시 강남구 삼성동 16-1 강남구청\", cat)\n",
    "    \n",
    "'''\n",
    "결과 \n",
    "\n",
    "dic = {'1인분주문': 530,\n",
    " '프랜차이즈': 818,\n",
    " '치킨': 331,\n",
    " '피자양식': 571,\n",
    " '중식': 210,\n",
    " '한식': 1614,\n",
    " '일식돈까스': 607,\n",
    " '족발보쌈': 126,\n",
    " '야식': 677,\n",
    " '분식': 666,\n",
    " '카페디저트': 727,\n",
    " '편의점': 80}\n",
    "\n",
    "'''\n",
    "\n",
    "# 카테고리별로 url 수집\n",
    "# 맨 아래까지 스크롤 시 60개씩 동적으로 가게 추가 표시되어 컴퓨터에 상당한 무리가 가며, 해당 가게에 접속하여 url 수집 후 되돌아오면 세션이 초기화 됨\n",
    "# 에러 핸들링을 위하여 100개씩 나누어서 수집\n",
    "for cat in categories:\n",
    "    review_num = dic[cat]\n",
    "    temp = review_num\n",
    "    n = 1\n",
    "    for i in range(review_num//100+1):\n",
    "        print(n, temp)\n",
    "        if temp < 100:\n",
    "            get_url3(\"서울특별시 강남구 삼성동 16-1 강남구청\", cat, n, review_num+1)\n",
    "            break\n",
    "        get_url3(\"서울특별시 강남구 삼성동 16-1 강남구청\", cat, n, n+100)\n",
    "        n+=100\n",
    "        temp = review_num - n\n",
    "        \n",
    "\n",
    "# 수집된 url 데이터셋에 가게이름 추가\n",
    "for category in categories:\n",
    "    try:\n",
    "        get_name(category)\n",
    "    except:\n",
    "        print(category)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Find-A",
   "language": "python",
   "name": "finda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
